---
title: "ANÁLISIS Y PREDICCIÓN DE SERIES TEMPORALES"
date: "3/4/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE, warning=FALSE , message=FALSE}
library(readxl)
library(corrplot)
library(heatmaply)
library(RColorBrewer)
library(pastecs)
library(stats)
library(FactoMineR)
library(factoextra)
library(ggplot2)
library(lattice)
library(NbClust)
library(tidyverse)  
library(cluster)    
library(dendextend)
library(forecast)
```


# 1. Introducción: Presentación de la serie a analizar.

```{r }
# 1)
METRO <- read_excel("Metro.xlsx")
metro<-ts(METRO[,-1],start = c(2012,1),frequency = 12)
```

Los datos de la serie a analizar se organizan mensualmente. El número de valores es 108. He descargado los datos de ‘transporte urbano en metro’ de Sevilla, de 2012 a 2020, en la página web del INE (Instituto Nacional de Estadística). 

# 2. Representación gráfica y descomposición estacional (si tuviera comportamiento estacional).

```{r,Warning=F,Messages=F}
# 2.1)
autoplot(metro)+ ggtitle("Numero de viajeros mensuales por metro Sevilla") + xlab("Periodo") + ylab("Numero de viajeros por metro")

# 2.2)
metro_Comp<- decompose(metro,type=c("multiplicative"))
autoplot(metro_Comp,ts.colour = "blue")

# 2.3)
knitr::kable(metro_Comp$figure, digits =2,caption = "Coef Estacionalidad")

# 2.4) 
print(metro_Comp)

# 2.5)
autoplot(metro, series="Datos") +
autolayer(trendcycle(metro_Comp), series="Tendencia")+ autolayer(seasadj(metro_Comp), series="Estacionalmente ajustada")+ xlab("Year") + ylab("Viajeros") +
ggtitle("Serie de vuelos") + scale_colour_manual(values=c("gray","blue","red"), breaks=c("Datos","Estacionalmente ajustada","Tendencia"))

# 2.6)
ggseasonplot(metro, year.labels=TRUE, year.labels.left=TRUE) + ylab("Número") +
ggtitle("Seasonal plot: viajeros metro Sevilla")
```

Nos centramos en la serie viajeros en metro en Sevilla. En primer lugar, realizamos la descomposición estacional según el modelo multiplicativo. Después, representamos los componentes de la serie obtenidos.

En la gráfica que representa la estacionalidad, podemos ver que es la representación de los coeficientes estacionales, por lo que se repite de manera constante.

Según los coeficientes de estacionalidad observemos que el mayor es 1.93, que corresponde al mes de agosto. El menor de los coeficientes es el del mes de enero, 0.46.

Recordamos que para estudiar el comportamiento estacional resulta útil la representación gráfica de los valores de la serie, dibujando cada año en un color diferente. Como podemos ver, los años tienen la misma estructura, salvo en 2012, en la gráfica de los valores de la serie dibujado cada año en un color diferente, y salvo el año 2020, año de la pandemia. Por otro lado, se ve que va aumentando el número de viajeros cada año.

En conclusion,  una serie temporal es el resultado de observar los valores de una variable a lo largo del tiempo en intervalos regulares. Por ello, la representación gráfica tiene un comportamiento estacional. De hecho, las fluctuaciones estacionales son aproximadamente constantes en el tiempo, salvo en el ggseasonplot.


# 3. Para comprobar la eficacia de los métodos de predicción que vamos a hacer en los siguientes apartados reservamos los últimos datos observados (un periodo en las series estacionales o aproximadamente 10 observaciones) para comparar con las predicciones realizadas por cada uno de los métodos. 

```{r }
# 3)
train <- window(metro, end=c(2018,12), frequency = 12)
```

Reservaremos los datos de 2019 y 2020 para no utilizarlos en el entrenamiento.

# 4. Encontrar el modelo de suavizado exponencial más adecuado. Para dicho modelo, representar gráficamente la serie observada y la suavizada con las predicciones para un periodo que se considere adecuado. 


```{r }
# 4.1) 
metro_s1=ses(train,alpha=NULL,h=24)
print(metro_s1)
autoplot(metro_s1) + autolayer(fitted(metro_s1), series="Fitted") + ylab("viajeros)") + xlab("ano")
knitr::kable(metro_s1$model$par, digits =4,caption = "Parámetros del modelo")

# 4.2)
metro_sh <- holt(train, h=24)
autoplot(metro_sh) + autolayer(fitted(metro_sh), series="Fitted") + ylab("viajeros)") + xlab("ano")
print(metro_sh)

# 4.3) 
metro_shd <- holt(train, damped=TRUE, h=24)
autoplot(metro_shd) + autolayer(fitted(metro_shd), series="Fitted") + ylab("viajeros)") + xlab("ano")
knitr::kable(metro_shd$model$par, digits =4,caption = "parámetros Damped holt")
knitr::kable(accuracy(metro_shd), digits =4,caption = "Medidas de bon dad del ajuste damped-holt")

# 4.4) 
metro_shw <- hw(train, h=24, seasonal="multiplicative",level = c(80, 95))
autoplot(metro_shw)
knitr::kable(metro_shw$model$par, digits =4,caption = "parámetros Holt-winters")
knitr::kable(accuracy(metro_shw), digits =4,caption = "Medidas Holt-winters")
knitr::kable(metro_shw, digits =4,caption = "Predicciones ")

# 4.5)
autoplot(train) + autolayer(metro_sh, series="Holt's method", PI=FALSE) + autolayer(metro_shd, series="Damped Holt's method", PI=FALSE) + ggtitle("Forecasts from Holt's method") + xlab("Ano") + ylab("Viajeros") + guides(colour=guide_legend(title="Forecast"))
```

Observemos con el método suavizado exponencial simple que la predicción permanece constante para todos los años. Vemos también que los valores ajustados y las predicciones con este método no son muy buenos.

Por otra parte, vemos que el método de la función holt da unas predicciones más adecuadas, puesto que tiene en cuenta los cambios en la tendencia.

Pero si queremos predecir el número de viajeros en el metro de Sevilla un año después del último observado, utilizaremos el modelo de Holt-winters multiplicativo porque la serie es estacional. 

Como podemos observar en las gráficas, este método da unas predicciones más adecuadas puesto que tiene en cuenta los cambios en la tendencia. Así que comprobamos en la representación gráfica final que el modelo de suavizado exponencial más adecuado es el Holt-Winters. De hecho, es fqvorqble a la hora de predecir los picos estacionales del periodo elegido.

Comprobamos nuestra observación con otra representación gráfica a continuación:


```{r }
# 4.6)
LESB=HoltWinters(train)
plot(LESB)

# 4.6)
metroforecast= forecast(LESB,h=24)
plot(metroforecast)
```

La representación confirma nuestra observación, el modelo de suavizado exponencial más adecuado es el Holt-Winters.

# 5. Representar la serie y los correlogramas. Decidir que modelo puede ser ajustado. Ajustar el modelo adecuado comprobando que sus residuales están incorrelados. (Sintaxis, tablas de los parámetros estimados y gráficos).

```{r} 
# 5.1)
corr<-Acf(train, lag=10)
print(corr)

corrp<-Pacf(train, lag=10) 
print(corrp)

# 5.1.1) 
ggAcf(train, lag=48)

# 5.1.2) 
ggPacf(train, lag=48)

# 5.1.3)
autoplot(train)+ ggtitle("Porcentaje de metro") + xlab("anos") + ylab("porcentaje")

# 5.2)
# 5.2.1) 
ggAcf(diff(train), lag=48)

# 5.2.2)
ggPacf(diff(train), lag=48)

# 5.3.3 
autoplot(diff(train))+ ggtitle("Porcentaje de metro") + xlab("anos") + ylab("porcentaje")

# 5.3)
# 5.3.1)
ggAcf(diff(diff(train),12), lag=48)

# 5.3.2)
ggPacf(diff(diff(train),12), lag=48)

# 5.3.3)
autoplot(diff(diff(train),12))+ ggtitle("Porcentaje de viajeros") +
xlab("anos") + ylab("porcentaje")

```

- En el autocorrelograma simple, se observa un comportamiento repetitivo de las autocorrelaciones cada 12 meses. Puesto que en el gráfico de la serie hemos visto que la media no es constante porque la serie tiene tendencia y el ACF decrece de forma lenta, es necesario hacer una diferenciación  Además, el autoplot muestra una clara no estacionariedad.

- En la serie diferenciada, mediante una diferenciación de orden estacional, podemos ver que el comportamiento es parecido al autocorrelograma simple.

- Con la serie doblemente diferenciada vemos que el proceso ya es estacionario. Observamos que las autocorrelaciones decrecen de forma más rápida: el ACF se corta después del 1 y el PACF corta después del 2. Por ello, nuestro candidato a ajustar sera: ARIMA(1,1,0)(0,1,1)12.

Vamos a usar la función auto.arima. Esta función busca a través de combinaciones de parámetros de pedido y selecciona el conjunto que optimiza los criterios de ajuste del modelo. De hecho, la función auto.arima encuentra el mejor modelo Arima ajustando todos los órdenes hasta que consigue que los residuos están incorrelados.


```{r}
# 5.4)
# Model 1
fit <- auto.arima(train)
checkresiduals(fit)

# Model 1 (log)
fit1 <- auto.arima(log(train)) 
checkresiduals(fit1)

# Model 2 - Ajuste del ARIMA(1,1,0)
fit2 <- Arima((train),c(1,1,0),seasonal=c(0,1,1)) 
checkresiduals(fit2)

# 5.5) 
knitr::kable(accuracy(fit), digits =4,caption = "Medidas de ajuste")
```

Puesto que el contraste de Ljung-Box nos da un p-valor >0.05 en el Modelo 1, aceptamos la hipótesis de que los residuos están incorrelados, lo que también podemos ver en su autocorrelograma.

Por otro lado, el modelo 2 (fit2) da una autocorrelación, ya que que el pvalor es mucho menor de 0.05 rechazamos que los residuos están incorrelados, lo que implica que el modelo no explica toda la dependencia de la serie. Rechazamos el modelo 2.

Finalmente, los residuos son independientes y que el modelo 1 (fit) y el modelo 1 (fit1) log respetan la hipótesis. Elegimos el modelo 1, lo confirma la autocorrelation test box pierce, ya que el valor p es mayor que 0.05 (0.9361).

En conclusión, el modelo 1 (fit) puede valer.

# 6. Calcular las predicciones y los intervalos de confianza para las unidades de tiempo que se considere oportuno, dependiendo de la serie, siguientes al último valor observado. Representarlas gráficamente. 

```{r }
# 6.1)
autoplot(forecast(fit,h=24))

# 6.2)
metropred=forecast(fit,h = 24)
plot(metropred)

# 6.3) 
predi<-forecast(fit,h=24) 
knitr::kable(predi, digits =4,caption = "Predicciones ")

# 6.4) 
predi3<-forecast(fit,h=24) 
cbind("predicion" =exp(predi3$mean),"L80" = exp(predi3$lower),"U80" = exp(predi3$upper)) %>%knitr::kable(caption = "Predicciones ")
```

Calculando las predicciones y los intervalos de confianza para las unidades de tiempo, podemos concluir que la diferencia entre los valores de pronóstico dados por este modelo y la observación que tuvimos son aceptables. 


# 7. Comparar las predicciones obtenidas con cada uno de los métodos con los valores observados que habíamos reservado antes. Conclusiones.

```{r }
# 7.1) 
autoplot(metro) + autolayer(forecast(fit ,h=24), series="Modelo 1 (fit)", PI=FALSE) + autolayer(forecast(fit2 ,h=24), series="Modelo 2 (fit2)", PI=FALSE) + ggtitle("Prediciones para diferentes modelos ") + guides(colour=guide_legend(title="Forecast")) 
```

Acabamos de comparar las predicciones obtenidas con cada uno de los métodos, con los valores observados que habíamos reservado antes.

Observamos en esta comparación que el Modelo 1 es el mejor modelo.

A continuación, vamos a comparar el modelo Holt-Winters con el Modelo 1 (fit):

```{r }
# 7.2) 
autoplot(metro) + autolayer(forecast(metro_shw ,h=24), series="Holt-Winters", PI=FALSE) + autolayer(forecast(fit ,h=24), series="Modelo 1 (fit)", PI=FALSE) + ggtitle("Prediciones para diferentes modelos ") + guides(colour=guide_legend(title="Forecast"))
```

Según la representación gráfica, observamos de nuevo que el modelo de Arima - Modelo 1 - está más adaptado a los valores de observación de nuestra serie, ya que el Modelo 1 se ajusta mejor que el gráfico de Holt-winters de la serie, sobre todo antes de 2020.

Para terminar, vemos que hay una diferencia importante entre la predicción de ambos modelos en 2020 y los valores observados debido a la pandemia y al número de usuarios de metro en Sevilla que disminuyó por consecuencia.


